{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": " #导入需要的模块\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 用来绘图的，封装了matplot\n# 要注意的是一旦导入了seaborn，\n# matplotlib的默认作图风格就会被覆盖成seaborn的格式\nimport seaborn as sns       \n\nfrom scipy import stats\nfrom scipy.stats import  norm\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline  \n# 为了在jupyter notebook里作图，需要用到这个命令",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38a3322b89a7d35908cc87e68c91d4705ccd8d70"
      },
      "cell_type": "code",
      "source": "df = pd.read_csv(\"../input/train.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "663ebf904d7d8e10e624901864eac438cc26367d"
      },
      "cell_type": "code",
      "source": "xnewdf = pd.DataFrame(df,columns=['GrLivArea','TotRmsAbvGrd','FullBath','TotalBsmtSF','GarageCars','YearBuilt','OverallQual'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "cf0c1e8d282c8ab6a9874e1ad899d1d6d945f4d1"
      },
      "cell_type": "code",
      "source": "ynewdf = pd.DataFrame(df,columns=['SalePrice'])\nynewdf=ynewdf.values.reshape(-1,1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e96eb3637ccc57ffee9d1793fee30f355810de22"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler  # 归一化的库\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVR                     # svr的库\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "44bd77963dc8df90b2b8b82fba681a3bacbb5a0e"
      },
      "cell_type": "code",
      "source": " X_train, X_test, y_train, y_test = train_test_split(xnewdf, ynewdf, test_size=.4, random_state=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90b458302b3395494a2735c2386eecf1d9a4c06b"
      },
      "cell_type": "code",
      "source": "# 数据标准化\nscaler=MinMaxScaler(feature_range=(0,1))\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)\ny_train=scaler.fit_transform(y_train)\ny_test=scaler.fit_transform(y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "7ff427dc06f85d240dacea55453f1e770e53feaa"
      },
      "cell_type": "code",
      "source": "clf = SVR(kernel='rbf').fit(X_train, y_train)\nclf.score(X_test, y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb766cd06a23584c269c80ad6629db7f883e8c14"
      },
      "cell_type": "code",
      "source": "# 交叉验证\n# clf = SVR(kernel='rbf')\n# scores = cross_val_score(clf, X_train, y_train, cv=5)\n# scores.mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06c5932d0d5c6275f621867895501eb701f15f12"
      },
      "cell_type": "code",
      "source": "# 保存模型\nfrom sklearn.externals import joblib\njoblib.dump(clf,'oldsvr.model')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd7cfd4a6e0cbafd12ce162396c0b20c0ee9dfaa"
      },
      "cell_type": "code",
      "source": "from math import exp ,log ,sqrt,copysign\nimport random\n# algorithm_34 CDOL\ndef pro_f(z):\n    # this is the projection function\n    temp = min(1, (z + 1) / 2)\n    return max(0, temp)\n\n\ndef dot_mul(x1, x2):\n    # 行向量乘以列向量结果是一个实数\n    if len(x1) != len(x2):\n        print(\"those Vectors latitudes are not same!!! in dot_mul\")\n    result = 0\n    for i in range(len(x1)):\n        result = result + x1[i] * x2[i]\n    return result\n\n\ndef sign(x):\n    if x > 0:\n        return 1\n    elif x < 0:\n        return -1\n    else:\n        return 0\n\n\ndef st(xw, real_yt):\n    temp = 0.5 * (pro_f(xw)-pro_f(real_yt)) * (pro_f(xw)-pro_f(real_yt))\n    return exp(temp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28f8905d3aaa6e6c20e069bc4fa5ab66939af042"
      },
      "cell_type": "code",
      "source": "class KernelInfo:\n\n    def __init__(self, tao, flag, x, type = \"e\"):\n        self.tao = tao      # 该支持向量前面的系数\n        self.flag = flag          # 该支持向量的标签值（对于分类问题来说就是真实的标签，而对于回归问题来说，这个y值是sign(y_real-y_pre)表示的是margin的正负\n        self.x = x          # 支持向量\n        self.type = type    # 所使用的核函数类型",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "5b5a3ec71a049c71468e568a87d4a3aebf9ed996"
      },
      "cell_type": "code",
      "source": "class TOL:\n\n    def __init__(self, ee, ploy_y, ploy_d, ploy_r, e_y, sig_y, tao, C, maxS):\n        \n        self.ee = ee    # 超参数，ee是svr的管道宽度\n        self.alpha11 = 0.5\n        self.alpha22 = 0.5\n        self.ploy_y = ploy_y    # 多项式核的超参数y\n        self.ploy_d = ploy_d    # 多项式核的超参数d\n        self.ploy_r = ploy_r    # 多项式核的超参数r\n        self.e_y = e_y          # 径向基核的超参数e_y\n        self.sig_y = sig_y      # sigmoid核超参数sig_y\n        self.tao = tao          # 最新的（即t时刻）svr多项式的每一项前面的系数tao\n        self.C = C              # 松弛变量前面的超参数C\n        self.B = []             # B的每一元素都是KernelInfo类，里面保存了每一个时刻的支持向量的信息\n        self.maxS = maxS        # 支持向量集合B\n        self.S = 0              # 当前支持向量集合的大小\n        \n        self.set_old_wx = []\n        self.set_new_wx = []\n        self.set_old_yt = []\n        self.set_real_yt = []\n        \n        self.cont = 0 #计数值，记录训练轮数的\n        # -------------------------------------------------------------------\n\n        self.f = []      # the model-function of non-linear PA\n\n        #self.b = []      # the list of parameter of non-linear PA\n\n    # end _int_\n\n    def kernel_liner(self, x1, x2):\n        return dot_mul(x1, x2)\n\n    def kernel_polynomial(self, x1, x2):\n        temp = self.ploy_y * dot_mul(x1, x2) + self.ploy_r\n        return temp**self.ploy_d\n\n    def kernel_e(self, x1, x2):\n        temp=0\n        for i in range(len(x1)):\n            temp = (x1[i] - x2[i]) * (x1[i] - x2[i])+temp\n        temp = -(self.e_y * temp)\n        temp = exp(temp)\n        return temp\n\n    def kernel_sig(self, x1, x2):\n        temp = self.sig_y * dot_mul(x1, x2)\n        temp = (exp(temp) - exp(-temp))/(exp(temp) + exp(-temp))\n        return temp\n\n    def cal_tao(self, loss, xt):\n        temp = loss / sqrt(dot_mul(xt, xt))       # type change?? should I force this type to float??\n        temp = min(self.C, temp)\n        return temp\n\n    def new_loss(self, xt, real_yt):\n        # 第几轮\n        self.cont = self.cont+1\n        # 根据旧的分类器预测出一个值，记为old_wx\n        old_model = joblib.load('oldsvr.model')\n        old_wx = old_model.predict([xt])\n        new_wx = 0.5\n        \n        temp_cor =[]  # 由于在线核PA算法发生维度爆炸，为了防止起数据波动太大，这个是存放归一化之前的数据的容器\n        temp_cor_tao = []\n\n        # 每算一步都要对tao进行标准化\n        \n#         for i in range(len(self.B)):\n#             temp_cor_tao.append(self.B[i].tao)\n#         if len(temp_cor_tao)!=0:\n#             temp_cor_tao=np.array(temp_cor_tao)\n#             temp_cor_tao=scaler.fit_transform(temp_cor_tao.reshape(-1,1))\n#         for i in range(len(self.B)):\n#             self.B[i].tao = temp_cor_tao[i]\n            \n            \n        # 根据在线核PA算法预测出另一个值,记为new_wx\n        for i in range(len(self.B)):\n            new_wx = self.B[i].tao * self.B[i].flag * self.kernel_e(xt, self.B[i].x)+new_wx\n            \n        # 每算一步都要进行标准化，将其结果映射到01区间中去，这样应该可以保证不会发生数值范围的巨大波动（应该可以吧。。但我觉得这不靠谱）\n#         for i in range(len(self.B)):\n#             temp_cor.append(self.B[i].tao * self.B[i].flag * self.kernel_e(xt, self.B[i].x))\n            \n#         if len(temp_cor)!=0:\n#             temp_cor=np.array(temp_cor)\n#             temp_cor=scaler.fit_transform(temp_cor.reshape(-1,1))\n#             new_wx=sum(temp_cor)[0]\n\n        # 根据在线迁移学习算法HomOTL-I求出联合的预测结果yt\n        yt = self.alpha11 * pro_f(old_wx) + self.alpha22 * pro_f(new_wx)   # 这个是分类函数，如果是回归函数的应该还要修改\n        \n        flag = sign(real_yt-yt)\n        \n        print('旧svr模型预测值:',old_wx,'在线学习预测值:',new_wx,'在线迁移学习预测值:',yt,'真实值:',real_yt)\n        \n        \n        self.set_old_wx.append(old_wx)\n        self.set_new_wx.append(new_wx)\n        self.set_old_yt.append(yt)\n        self.set_real_yt.append(real_yt)\n        \n        # 在线学习部分，求新旧预测结果的新权重\n        temp1 = self.alpha11 * st(old_wx, real_yt)\n        temp2 = self.alpha22 * st(new_wx, real_yt)\n        new_alpha11 = temp1 / (temp1 + temp2)\n        new_alpha22 = temp2 / (temp1 + temp2)\n        self.alpha11 = new_alpha11\n        self.a1pha22 = new_alpha22\n\n        # 在线学习部分：计算损失函数loss，更新tao值\n        # loss = max(0, 1 - real_yt * new_wx) # 这个是分类问题的损失函数\n        loss = max(0,abs(new_wx-real_yt)-self.ee)\n        self.tao = self.cal_tao(loss, xt)\n\n        # 在线学习部分，根据固定缓冲器的核在线学习算法更新在线学习的学习器\n        if loss > 0: # prediction result is worry\n            # 注意，对于非线性核来说，在B中增加支持向量就是相当于更新 w_t+1= w_t+tao*y*t\n            new_support_vector = KernelInfo(self.tao, flag, xt) # 初始化新的支持向量（新建类KernelInfo）包含成员tao，real_yt,xt\n            self.B.append(new_support_vector)      # 将新的支持向量加入到支持集合B中\n            self.S = self.S +1                     # 将支持向量数量加1\n            if self.maxS <= self.S:                # r如果支持向量的数量大于最大阈值，则需要随机剔除一个向量\n                print('')\n                sel_x = self.B.pop(random.randint(0, len(self.B)-1))  # 在B的list中随机挑一个元素\n                self.S = self.S - 1                # \n                self.f.append(new_support_vector)  # 加入新的支持向量\n                self.f.remove(sel_x)    # it is OK ??? 删除旧的支持向量\n            else:\n                self.f.append(new_support_vector) # 如果没满的话就直接加入到B中\n            # end_if\n        # end_tol\n\n    def tol_worry(self, xt, real_yt):\n        pass",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "987ffbf209cc8af3155c26e69d2aed30dfb48487"
      },
      "cell_type": "code",
      "source": "#   def _init_(self, ee,  ploy_y, ploy_d, ploy_r, e_y, sig_y, tao, C, maxS):\n\n'''\n\n        self.ee = ee    # 超参数，ee是svr的管道宽度\n        self.a1pha11 = 0.5  # 迁移学习的老模型的参数，初始值为0.5\n        self.alpha22 = 0.5  # 迁移学习的新模型的参数，初始值为0.5\n        self.ploy_y = ploy_y    # 多项式核的超参数y\n        self.ploy_d = ploy_d    # 多项式核的超参数d\n        self.ploy_r = ploy_r    # 多项式核的超参数r\n        self.e_y = e_y          # 径向基核的超参数e_y,从网上查的资料说libsvm里面e的值默认是1/k（其中k是类别数\n        self.sig_y = sig_y      # sigmoid核超参数sig_y\n        self.tao = tao          # 最新的（即t时刻）svr多项式的每一项前面的系数tao\n        self.C = C              # 松弛变量前面的超参数C\n        self.B = []             # B的每一元素都是KernelInfo类，里面保存了每一个时刻的支持向量的信息\n        self.maxS = maxS        # 支持向量集合B\n        self.S = 0              # 当前支持向量集合的大小\n        \n        我用的是径向基核函数，所以初始化其他核的参数就为0了\n        参数设置说实话我一点谱也没有，完全是根据网上的经验给的\n        超参数ee为0.1\n        径向基核函数的超参数为0.1\n        松弛变量前面的超参数C为0.5（我感觉有点太小了，但是如果这个数大了的话PA的结果更离谱）\n        支持向量集合最大容量为13（太大不好）\n        \n'''\n\n\nbustol = TOL(0.1, 0,0,0, 0.1,0,0, 0.5 ,13)  # 初始化TOL实例，设置参数\n\n# 模仿在线的形式进行在线迁移学习预测\nfor i in range(len(X_test)):\n    bustol.new_loss(X_test[i],y_test[i])\n\nplt.figure(figsize=(20,7))\nplt.plot(list(range(len(bustol.set_old_wx))), bustol.set_old_wx, color='b',label=\"offline svr prediction\")    # svr的预测值 set_old_yt\nplt.plot(list(range(len(bustol.set_new_wx))),bustol.set_new_wx , color='r',label=\"PA prediction\")  #红线在线PA算法的预测值 set_real_yt\nplt.plot(list(range(len(bustol.set_real_yt))),bustol.set_real_yt , color='g',label=\"real value\") # 绿线为真实值\nplt.plot(list(range(len(bustol.set_old_yt))),bustol.set_old_yt , color='y',label=\" online transfer learning prediction\") # 黄线为在线迁移学习的预测值\nplt.xlabel(\"the sequence of instance\")\nplt.ylabel(\"values\")\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}