{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import to_numeric\n",
    "from numpy import split\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load all data\n",
    "dataset = pd.read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "\tone_day = 60 * 24\n",
    "\tfor row in range(values.shape[0]):\n",
    "\t\tfor col in range(values.shape[1]):\n",
    "\t\t\tif isnan(values[row, col]):\n",
    "\t\t\t\tvalues[row, col] = values[row - one_day, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mark all missing values\n",
    "dataset.replace('?', nan, inplace=True)\n",
    "# make dataset numeric (数值化)\n",
    "dataset = dataset.astype('float32') # 将数据集的所有数据转化为ｆｌａｏｔ３２类型\n",
    "# fill missing\n",
    "fill_missing(dataset.values)\n",
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n",
    "# save updated dataset\n",
    "dataset.to_csv('household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 8)\n",
      "            Global_active_power  Global_reactive_power        Voltage  \\\n",
      "datetime                                                                \n",
      "2006-12-16          1209.175999                 34.922   93552.529953   \n",
      "2006-12-17          3390.460002                226.006  345725.320053   \n",
      "2006-12-18          2203.826000                161.792  347373.640137   \n",
      "2006-12-19          1666.194001                150.942  348479.009842   \n",
      "2006-12-20          2225.748000                160.998  348923.610077   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
      "datetime                                                                       \n",
      "2006-12-16       5180.800003             0.0           546.0          4926.0   \n",
      "2006-12-17      14398.600012          2033.0          4187.0         13341.0   \n",
      "2006-12-18       9247.199997          1063.0          2621.0         14018.0   \n",
      "2006-12-19       7094.000005           839.0          7602.0          6197.0   \n",
      "2006-12-20       9313.000001             0.0          2648.0         14063.0   \n",
      "\n",
      "            sub_metering_4  \n",
      "datetime                    \n",
      "2006-12-16    14680.933325  \n",
      "2006-12-17    36946.666703  \n",
      "2006-12-18    19028.433311  \n",
      "2006-12-19    13131.900035  \n",
      "2006-12-20    20384.799997  \n"
     ]
    }
   ],
   "source": [
    "# resample minute data to total for each day\n",
    "from pandas import read_csv\n",
    "# load the new file\n",
    "dataset = read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset这个数据集是一个1442*8的数组\\n而dataset经过split_dataset函数后被分成了再次划分成了7份(split函数从左到右划分，故先将第一维的1442划分成了7份，而不是对第二维的8划分)，\\n划分之后我们旧得到了train数据集，后面出现的数据扁平化(flatten data)实际上就是将train的结构还原为dataset的结构.\\ntrain.shape为(159, 7, 8)\\ntest.shape为(46, 7, 8)\\ntrain训练集是一个三维的结构\\n三个维度分别代表了:batch的数量，滑动窗口的大小，每一个样例的特征数量\\nbatch是训练\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dataset这个数据集是一个1442*8的数组\n",
    "而dataset经过split_dataset函数后被分成了再次划分成了7份(split函数从左到右划分，故先将第一维的1442划分成了7份，而不是对第二维的8划分)，\n",
    "划分之后我们旧得到了train数据集，后面出现的数据扁平化(flatten data)实际上就是将train的结构还原为dataset的结构.\n",
    "train.shape为(159, 7, 8)\n",
    "test.shape为(46, 7, 8)\n",
    "train训练集是一个三维的结构\n",
    "三个维度分别代表了:batch的数量，滑动窗口的大小，每一个样例的特征数量\n",
    "batch是训练\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm: [397.186] 409.4, 407.7, 375.2, 391.2, 400.4, 328.9, 456.3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sun'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f666fce3ff89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# plot scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'thr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fri'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \"\"\"\n\u001b[0;32m-> 1815\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \"\"\"\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/public/anaconda3/envs/TOL/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'sun'"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "# 训练集划分，将单变量数据集划分为池训练集和测试集\n",
    "# 并且还有一点值得说明，训练LSTM的时候我们是以一天为step的训练的，而预测的时候是一周为step进行预测的，这也就是为什么要按周split数据集的原因\n",
    "def split_dataset(data):\n",
    "\t# 讲前三年的数据作为训练集，将最后一年的数据作为测试集\n",
    "\ttrain, test = data[1:-328], data[-328:-6]\n",
    "\t# 将训练数据重组为以周为单位的数据\n",
    "    # split函数是一个numpy库的函数，其作用是把一个array从左到右按顺序切分，其\n",
    "    # 切分长度不能超过array的元素个数,axis默认为０，即横向切分\n",
    "\ttrain = array(split(train, len(train)/7))\n",
    "\ttest = array(split(test, len(test)/7))\n",
    "\treturn train, test\n",
    " \n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "# 根据预期值评价单周预测或者多周预测\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    # 参数说明：actual是实际值，predicted是预测值\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "    # 为每一日的预测值计算ＲＭＳＥ(均方根误差)评分\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# 计算平方误差\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# 计算均方根误差\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# 储存到scores容器中\n",
    "\t\tscores.append(rmse)\n",
    "\t# 计算全体全体测试集和预测值的均方根误差\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    " \n",
    "# 计算得分的总和\n",
    "def summarize_scores(name, score, scores):\n",
    "    # join函数(python系统自带函数)是将列(list)表转化为字符串的函数，单引号中的逗号是分隔符。\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "    \n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    # 参数说明:n_input是滑动窗口大小,n_out是未来预测的步长，默认为7即说明我们要预测未来7天，即一周，的数据。\n",
    "\t# flatten data,数据扁平化\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor _ in range(len(data)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tin_end = in_start + n_input  # 预测的输入窗口截止索引(输入窗口大小：in_end-in_start=7)\n",
    "\t\tout_end = in_end + n_out     # 预测的输出窗口截止索引(输出窗口大小：out_end-in_end=7)\n",
    "\t\t# ensure we have enough data for this instance，保证输出窗口的移动不会超过数据集的边界\n",
    "\t\tif out_end < len(data):\n",
    "\t\t\tx_input = data[in_start:in_end, 0]  # 由于是单特征预测，所以这里只取一个特征,x_input的结构是[1,2,...,8]这样的结构\n",
    "            # 下面rashape的目的是将输出数据x_input转化为2d的形式，即[[1],[2],[3],..,[8]]的形式，这个是为了满足keras模型的输入\n",
    "\t\t\tx_input = x_input.reshape((len(x_input), 1))   # 这里要注意len()一个多维数组返回的是其最外层的维度大小\n",
    "\t\t\tX.append(x_input)\n",
    "\t\t\ty.append(data[in_end:out_end, 0])  # 标签y无需转化为2D形式\n",
    "\t\t# move along one time step\n",
    "\t\tin_start += 1\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "\t# prepare data,将时间序列数据转化为符合监督学习的格式\n",
    "\ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\t# define parameters，确定参数\n",
    "\tverbose, epochs, batch_size = 0, 70, 16\n",
    "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\t# define model，定义模型结构\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit network，拟合网络\n",
    "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model\n",
    "\n",
    "'''\n",
    "\n",
    "python不允许程序员选择采用传值还是传引用。\n",
    "Python参数传递采用的肯定是“传对象引用”的方式。\n",
    "这种方式相当于传值和传引用的一种综合。\n",
    "如果函数收到的是一个可变对象（比如字典或者列表）的引用，\n",
    "就能修改对象的原始值－－相当于通过“传引用”来传递对象。\n",
    "如果函数收到的是一个不可变对象（比如数字、字符或者元组）的引用，\n",
    "就不能直接修改原始对象－－相当于通过“传值'来传递对象。\n",
    "\n",
    "'''\n",
    "# make a forecast，进行一次预测\n",
    "'''\n",
    "forecast函数的预测规则：\n",
    "n_input是滑动窗口的大小，即我们每次用最后n_input个周的历史数据去预测下一个周的数据，这个“历史数据”就来自\n",
    "evaluate_model中history集合，即每次都用离待预测数据最近的n_input个连续数据去预测接下来最近时刻的情况，\n",
    "这样充分利用了数据之间的时序信息，体现了时间序列模型与其他回归模型在实现上的不同。\n",
    "'''\n",
    "def forecast(model, history, n_input):\n",
    "\t# flatten data，数据扁平化\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data，从输入数据中提取最近的观测值\n",
    "\tinput_x = data[-n_input:, 0]\n",
    "\t# reshape into [1, n_input, 1]，讲数据变换成符合lstm模型的输入格式\n",
    "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
    "\t# forecast the next week,预测下一周的数据\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast，这个地方不太清楚，为什么只取第一项，应该和model.predict的返回值有关\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat\n",
    " \n",
    "# evaluate a single model\n",
    "# 使用的是前移评价(Walk Forward Validation)方法(时间序列模型中的k折交叉验证)\n",
    "'''\n",
    "evaluate_model中history数据集合的作用和更新规则:\n",
    "在最初history是等于训练集train的，随后，在每一轮的预测中，每取出一个测试集的样例，在预测函数forcast调用结束\n",
    "之后就将其加入到history集合中,最后history=train+test\n",
    "\n",
    "'''\n",
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "    # 注意这里为什么不写成history=train,因为python中只有引用，没有赋值,所以必须将train\"复制\"一份才可以赋值给history\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week，对每一次预测都进行前移评价\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week,得到一个test样例的预测结果\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions，储存预测结果\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week，讲该test样例当做历史数据加入到history数据集中作为下一次预测的输入\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week，对每一周的预测结果进行评价\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores\n",
    " \n",
    "# load the new file\n",
    "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# evaluate model and get scores\n",
    "n_input = 7\n",
    "score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
